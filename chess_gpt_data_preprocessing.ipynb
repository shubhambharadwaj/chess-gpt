{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67a071c2-3d52-4f49-8e87-234c9e1ddca1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Install Libraries and Define constants and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "65f87a7b-a587-43ff-a1db-b738f916917a",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install Required Libraries and unzip to move files inside tar.gz"
    }
   },
   "outputs": [],
   "source": [
    "%pip install zstandard python-chess tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "902c4522-0b04-44ea-857b-af7b1b2025b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70779f9a-7859-4264-9889-127c3e1024e0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Import Libraries and define constants"
    }
   },
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "import chess\n",
    "import pickle\n",
    "import random\n",
    "import chess.pgn\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import zstandard as zstd\n",
    "PARENT_CHESS_GPT = '/Volumes/unitygo/lichess/engine/chessgpt'\n",
    "CHESS_GPT_SFT = '/Volumes/unitygo/lichess/engine/chessgpt/chessgpt_sft_data/'\n",
    "CHESS_GPT = '/Volumes/unitygo/lichess/engine/chessgpt/chessgpt_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8f2e839-95b4-42e5-b494-f2da8ed2d32b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_lichess_pgn(pgn_content):\n",
    "    \"\"\"\n",
    "    Parses a Lichess PGN file and returns structured data with headers, moves, comments, and game state.\n",
    "    Returns a list of games (for files with multiple games).\n",
    "    \"\"\"\n",
    "    games = []\n",
    "    pgn = io.StringIO(pgn_content)\n",
    "    while True:\n",
    "        game = chess.pgn.read_game(pgn)\n",
    "        if not game:\n",
    "            break\n",
    "        headers = dict(game.headers)\n",
    "        moves = []\n",
    "        board = game.board()\n",
    "        node = game\n",
    "        move_number = 1\n",
    "        while node.variations:\n",
    "            node = node.variation(0)\n",
    "            move = node.move\n",
    "            move_data = {\n",
    "                \"move_number\": move_number,\n",
    "                \"turn\": \"white\" if board.turn == chess.WHITE else \"black\",\n",
    "                \"san\": board.san(move),\n",
    "                \"uci\": move.uci(),\n",
    "                \"comment\": node.comment,\n",
    "                \"fen_before\": board.fen(),\n",
    "            }\n",
    "            try:\n",
    "                move_data[\"nags\"] = [chess.pgn.symbol_for_nag(nag) for nag in node.nags]\n",
    "            except:\n",
    "                move_data[\"nags\"] = []\n",
    "            # Update board state\n",
    "            board.push(move)\n",
    "            move_data[\"fen_after\"] = board.fen()\n",
    "            moves.append(move_data)\n",
    "            move_number += (0 if board.turn == chess.BLACK else 1)  # Increment after black moves\n",
    "        games.append({\n",
    "            \"headers\": headers,\n",
    "            \"moves\": moves,\n",
    "            \"termination\": headers.get(\"Termination\", \"\"),\n",
    "            \"result\": headers.get(\"Result\", \"\")\n",
    "        })\n",
    "    return games\n",
    "\n",
    "structured_game_data = []\n",
    "\n",
    "system_prompt = {\"role\": \"system\", \"content\": \"\"\"\n",
    "### INSTRUCTIONS:\n",
    "You are a professional chess commentator. Your task is to provide an in-depth analysis of the following chess game moves and overall board state. Follow these guidelines:\n",
    "\n",
    "1. Add detailed commentary related to the chess game moves, overall board state, player profile details like Elo rating, and tournament details if available, for example time control or game variant.\n",
    "2. Explain the opening principles, key middlegame plans, and the final outcome. \n",
    "3. Explain what the player might be thinking with each move on the game.\n",
    "4. Do not add any text before or after the list.\n",
    "5. Not every move is supposed to have a commentary, make sure you sound as human as possible.\n",
    "\"\"\"}\n",
    "def generate_commentary(pgn_text_user_message,pgn_text_assistant_prompt):\n",
    "    \"\"\"Converts a chess game JSON entry into a prompt-response format suitable for generating expert-level commentary.\"\"\"\n",
    "    user_prompt = {\"role\": \"user\", \"content\": str(pgn_text_user_message)}\n",
    "    assistant_prompt = {\"role\": \"assistant\", \"content\": str(pgn_text_assistant_prompt)}\n",
    "    return {'messages':[system_prompt, user_prompt, assistant_prompt]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1c3ab7ac-0138-41c4-92ce-61f006298c78",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Data Read and Conversion - Run only once as data gets saved into Volumes in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94962197-ac2f-42b1-8597-f2c81e995ee9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CHESS_CLIP = '/Volumes/unitygo/lichess/engine/chessgpt/chessclip_data/annotated_pgn/'\n",
    "for folder in os.listdir(CHESS_CLIP):\n",
    "    if 'tar.gz' in folder:\n",
    "        pass\n",
    "    else:\n",
    "        for file in tqdm(os.listdir(CHESS_CLIP+folder)):\n",
    "            try:\n",
    "                with open(f\"{CHESS_CLIP}{folder}/{file}\", encoding='latin-1') as f:\n",
    "                    pgn_content = f.read()\n",
    "                    games = parse_lichess_pgn(pgn_content)\n",
    "                    if games:\n",
    "                        structured_game_data.append(games[0])\n",
    "            except:\n",
    "                print(f\"{CHESS_CLIP}{folder}/{file}\")\n",
    "pickle.dump(structured_game_data, open(f\"{PARENT_CHESS_GPT}/structured_game_data.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cfdf8cd8-bac4-4610-882a-069679454a06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Prompt Design for Chat Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b63a848f-8f72-40ba-9604-b5cf77c22a0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "structured_game_data = pickle.load(open(f\"{PARENT_CHESS_GPT}/structured_game_data.pkl\", \"rb\"))\n",
    "output_dict_list_with_header = []\n",
    "updated_moves_list_with_header = []\n",
    "exclusion_header = ['Result','ECO','Opening','Termination','termination','result']\n",
    "structured_game_data_updated = []\n",
    "for item in structured_game_data:\n",
    "    item['headers'].pop('Annotator',None)\n",
    "    structured_game_data_updated.append(item)\n",
    "output_dict_list_with_header = copy.deepcopy(structured_game_data_updated)\n",
    "for item_2 in structured_game_data:\n",
    "    for x in exclusion_header:\n",
    "        item_2['headers'].pop(x,None)\n",
    "    updated_moves_list = []\n",
    "    for x in item_2['moves']:\n",
    "        x.pop('comment',None)\n",
    "        x.pop('nags',None)\n",
    "        updated_moves_list.append(x)\n",
    "    updated_moves_list_with_header.append({'headers':item_2['headers'],'moves':updated_moves_list})\n",
    "print(len(updated_moves_list_with_header),len(output_dict_list_with_header))\n",
    "len_moves = len(updated_moves_list_with_header)\n",
    "random_split = len_moves - random.randint(int(len_moves*0.05),int(len_moves*0.1))\n",
    "train_list_user,train_list_assistant = updated_moves_list_with_header[:random_split],output_dict_list_with_header[:random_split]\n",
    "eval_list_user,eval_list_assistant = updated_moves_list_with_header[random_split:],output_dict_list_with_header[random_split:]\n",
    "print(len(train_list_user),len(train_list_assistant),len(eval_list_user),len(eval_list_assistant))\n",
    "train_list = []\n",
    "eval_list = []\n",
    "for user,assistant in zip(train_list_user,train_list_assistant):\n",
    "    train_list.append(generate_commentary(user,assistant))\n",
    "for user,assistant in zip(eval_list_user,eval_list_assistant):\n",
    "    eval_list.append(generate_commentary(user,assistant))\n",
    "print(len(train_list),len(eval_list))\n",
    "train_df = spark.createDataFrame(pd.DataFrame(train_list))\n",
    "eval_df = spark.createDataFrame(pd.DataFrame(eval_list))\n",
    "train_df.write.mode('overwrite').saveAsTable(\"unitygo.lichess.chessgpt_chat_completion_train\")\n",
    "eval_df.write.mode('overwrite').saveAsTable(\"unitygo.lichess.chessgpt_chat_completion_eval\")\n",
    "display(train_df)\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ce26cc0b-81bf-4ced-9912-e357ff586a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# !rm /Volumes/unitygo/lichess/engine/chessgpt/train_data.jsonl\n",
    "# !rm /Volumes/unitygo/lichess/engine/chessgpt/merged_data.jsonl\n",
    "# !rm /Volumes/unitygo/lichess/engine/chessgpt/eval_data.jsonl\n",
    "\n",
    "# merge_file = '/Volumes/unitygo/lichess/engine/chessgpt/merged_data.jsonl'\n",
    "# train_file = '/Volumes/unitygo/lichess/engine/chessgpt/train_data.jsonl'\n",
    "# eval_file = '/Volumes/unitygo/lichess/engine/chessgpt/eval_data.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b8f069-04e1-4e6e-b37a-0cc9dad04c98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# def merge_jsonl_files(output_path, eval_path,input_dict): #, additional_files=[]\n",
    "#     eval_list = []\n",
    "#     train_list = []\n",
    "#     for category, file_list in input_dict.items():\n",
    "#         if category == 'annotated_pgn':\n",
    "#             for file_path in file_list:\n",
    "#                 if file_path.endswith('dataset_info.json'):\n",
    "#                     continue\n",
    "#                 else:\n",
    "#                     counter = 0\n",
    "#                     with open(file_path, 'r') as infile:\n",
    "#                         len_infile = sum(1 for _ in infile)\n",
    "#                         infile.seek(0)\n",
    "#                         random_split = len_infile - random.randint(int(len_infile*0.05),int(len_infile*0.1))\n",
    "#                         for line in infile:\n",
    "#                             if counter == random_split:\n",
    "#                                 eval_list.append(json.loads(line))\n",
    "#                             else:\n",
    "#                                 train_list.append(json.loads(line))\n",
    "#                                 counter += 1\n",
    "#     print(f\"Merged {len(train_list)} train lines and {len(eval_list)} eval lines\"            )                  \n",
    "#     with open(eval_path, 'w') as evalfile:\n",
    "#         for line in eval_list:\n",
    "#             #prompt_design = generate_commentary(line)\n",
    "#             #if prompt_design:\n",
    "#             json.dump(line, evalfile) #prompt_design\n",
    "#             evalfile.write(\"\\n\")\n",
    "\n",
    "#     with open(output_path, 'w') as outfile:\n",
    "#         for line in train_list:\n",
    "#             #prompt_design = generate_commentary(line)\n",
    "#             #if prompt_design:\n",
    "#             json.dump(line, outfile) #prompt_design\n",
    "#             outfile.write(\"\\n\")\n",
    "#         # if additional_files:\n",
    "#         #     for file_path in additional_files:\n",
    "#         #         try:\n",
    "#         #             with open(file_path, 'r') as infile:\n",
    "#         #                 for line in infile:\n",
    "#         #                     try:\n",
    "#         #                         json.loads(line)\n",
    "#         #                         outfile.write(line)\n",
    "#         #                     except json.JSONDecodeError:\n",
    "#         #                         print(f\"Invalid JSON in {file_path}, skipping line\")\n",
    "#         #         except FileNotFoundError:\n",
    "#         #             print(f\"File not found: {file_path}\")\n",
    "#         return train_list, eval_list\n",
    "# train_list, eval_list = merge_jsonl_files(train_file,eval_file, files_dict) #files_in_chess_gpt_sft\n",
    "# print(f\"Merged all JSONL files into {train_file} and {eval_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46b6ebfe-1462-4598-8f3d-a4c2b26c281c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Access structured data\n",
    "# for game in games:\n",
    "#     print(\"Headers:\", game[\"headers\"])\n",
    "#     print(\"Result:\", game[\"result\"])\n",
    "#     for move in game[\"moves\"]:\n",
    "#         print(f\"Move {move['move_number']} ({move['turn']}):\")\n",
    "#         print(f\"  SAN: {move['san']}\")\n",
    "#         print(f\"  Comment: {move['comment']}\")\n",
    "#         print(f\"  NAGs: {move['nags']}\")\n",
    "#         print(f\"  FEN Before: {move['fen_before']}\")\n",
    "#         print(f\"  FEN After: {move['fen_after']}\")\n",
    "#         print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b97ae46-481e-4ee8-a9d8-fe4ae06fb2a3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Rough Work for Reference"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install chess\n",
    "### !tar -xvzf /Volumes/unitygo/lichess/engine/chessgpt/chessclip_data/annotated_pgn/annotated_pgn_free.tar.gz -C /Volumes/unitygo/lichess/engine/chessgpt/chessclip_data/annotated_pgn/\n",
    "# import subprocess\n",
    "# CHESS_CLIP = '/Volumes/unitygo/lichess/engine/chessgpt/chessclip_data/annotated_pgn/'\n",
    "# !rm /Volumes/unitygo/lichess/engine/chessgpt/chessclip_data/annotated_pgn/gameknot/game_44.jsonl\n",
    "# for folder in os.listdir(CHESS_CLIP):\n",
    "#     if 'tar.gz' in folder:\n",
    "#         pass\n",
    "#     else:\n",
    "#         for file in os.listdir(CHESS_CLIP+folder):\n",
    "#             if 'game_44' in file:\n",
    "#                 print(CHESS_CLIP+folder+file)\n",
    "#             else:\n",
    "#                 continue\n",
    "#             awk_command = [\n",
    "#                             'awk',\n",
    "#                             '-v', 'FPAT=([^ ]*)|(\"[^\"]+\")',\n",
    "#                             '-f', '/Volumes/unitygo/lichess/engine/chessgpt/pgn_converter/convert_pgn_to_json.awk',\n",
    "#                             f'{CHESS_CLIP}{folder}/{file}'\n",
    "#                             ]\n",
    "#             # python_command = [\n",
    "#             #     'python',\n",
    "#             #     '/Volumes/unitygo/lichess/engine/chessgpt/pgn_converter/pgn_to_json.py',\n",
    "#             #     f'{CHESS_CLIP}{folder}/{file}',\n",
    "#             # ]\n",
    "#             result = subprocess.run(awk_command, text=True, capture_output=True)\n",
    "#             if result.returncode == 0:\n",
    "#                 print(\"Output:\\n\", result.stdout)\n",
    "#             else:\n",
    "#                 print(\"Error:\\n\", result.stderr)\n",
    "#             break"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3406832718991652,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "chess_gpt_data_preprocessing",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
